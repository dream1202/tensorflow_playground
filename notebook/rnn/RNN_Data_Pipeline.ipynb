{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 2 0 0 0]\n",
      " [1 2 3 0 0]\n",
      " [1 2 3 4 0]\n",
      " [1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "## BATCHING & PADDING DATA (high-level approach)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# [0, 1, 2, 3, 4 ,...]\n",
    "x = tf.range(1, 10, name=\"x\")\n",
    " \n",
    "# A queue that outputs 0,1,2,3,...\n",
    "range_q = tf.train.range_input_producer(limit=10, shuffle=False)\n",
    "slice_end = range_q.dequeue()\n",
    " \n",
    "# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\n",
    "y = tf.slice(x, [0], [slice_end], name=\"y\")\n",
    "\n",
    "    \n",
    "# Batch the variable length tensor with dynamic padding\n",
    "batched_data = tf.train.batch(\n",
    "    tensors=[y],\n",
    "    batch_size=6,\n",
    "    dynamic_pad=True,\n",
    "    name=\"y_batch\"\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        result = sess.run(batched_data)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    print(result)\n",
    "    coord.join(threads)\n",
    "\n",
    "# Run the graph\n",
    "# tf.contrib.learn takes care of starting the queues for us\n",
    "#res = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n",
    " \n",
    "# Print the result\n",
    "#print(\"Batch shape: {}\".format(res[0][\"y\"].shape))\n",
    "#print(res[0][\"y\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 2 0 0 0]\n",
      " [1 2 3 0 0]\n",
      " [1 2 3 4 0]\n",
      " [1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "## BATCHING & PADDING DATA (low-level approach)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# [0, 1, 2, 3, 4 ,...]\n",
    "x = tf.range(1, 10, name=\"x\")\n",
    " \n",
    "# A queue that outputs 0,1,2,3,...\n",
    "range_q = tf.train.range_input_producer(limit=10, shuffle=False)\n",
    "slice_end = range_q.dequeue()\n",
    " \n",
    "# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\n",
    "y = tf.slice(x, [0], [slice_end], name=\"y\")\n",
    "\n",
    "    \n",
    "# Batch the variable length tensor with PaddingFIFOQueue\n",
    "padding_q = tf.PaddingFIFOQueue(\n",
    "    capacity=10,\n",
    "    dtypes=tf.int32,\n",
    "    shapes=[[None]])\n",
    "enqueue_op = padding_q.enqueue([y])\n",
    "qr = tf.train.QueueRunner(padding_q, [enqueue_op])\n",
    "tf.train.add_queue_runner(qr)\n",
    "batched_data = padding_q.dequeue_many(6)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        result = sess.run(batched_data)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    print(result)\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Winston/workspace/LSTM/Sequence_test1.tfr\n"
     ]
    }
   ],
   "source": [
    "## SequenceExample (1: serialize/write part)\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sequences = [[1, 2, 3], [4, 5, 1], [1, 2], [0, 2, 4, 7], [9, 8], [5, 4, 3, 2, 1], [3, 6, 9]]\n",
    "label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1], [0, 1, 1, 0], [1, 0], [0, 1, 1, 0, 0], [1, 0, 1]]\n",
    "\n",
    "\n",
    "def make_sequence_example(inputs, labels):\n",
    "    # The object we return\n",
    "    ex = tf.train.SequenceExample()\n",
    "    # A non-sequential feature of our example\n",
    "    sequence_length = len(inputs)\n",
    "    ex.context.feature[\"length\"].int64_list.value.append(sequence_length)\n",
    "    # Feature lists for the two sequential features of our example\n",
    "    fl_inputs = ex.feature_lists.feature_list[\"inputs\"]\n",
    "    fl_labels = ex.feature_lists.feature_list[\"labels\"]\n",
    "    for _input, _label in zip(inputs, labels):\n",
    "        fl_inputs.feature.add().int64_list.value.append(_input)\n",
    "        fl_labels.feature.add().int64_list.value.append(_label)\n",
    "    return ex  \n",
    " \n",
    "# Write all examples into a TFRecords file\n",
    "output_file = os.path.join(os.getcwd(), 'Sequence_test1.tfr')\n",
    "print output_file\n",
    "writer = tf.python_io.TFRecordWriter(output_file)\n",
    "for sequence, label_sequence in zip(sequences, label_sequences):\n",
    "    ex = make_sequence_example(sequence, label_sequence)\n",
    "    writer.write(ex.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Winston/workspace/LSTM/Sequence_test1.tfr']\n",
      "('actual lengths =', array([3, 3, 2, 4]))\n",
      "('sequences = ', array([[1, 2, 3, 0],\n",
      "       [4, 5, 1, 0],\n",
      "       [1, 2, 0, 0],\n",
      "       [0, 2, 4, 7]]))\n",
      "('labels = ', array([[0, 1, 0, 0],\n",
      "       [1, 0, 0, 0],\n",
      "       [1, 1, 0, 0],\n",
      "       [0, 1, 1, 0]]))\n",
      "('actual lengths =', array([2, 5, 3]))\n",
      "('sequences = ', array([[9, 8, 0, 0, 0],\n",
      "       [5, 4, 3, 2, 1],\n",
      "       [3, 6, 9, 0, 0]]))\n",
      "('labels = ', array([[1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 0],\n",
      "       [1, 0, 1, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "## SequenceExample (2: deserialize/read part-1, leverage context feature in TFR)\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# A single serialized example\n",
    "# (You can read this from a file using TFRecordReader)\n",
    "#ex = make_example([1, 2, 3], [0, 1, 0]).SerializeToString()\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "file_list = [os.path.join(os.getcwd(), 'Sequence_test1.tfr')]\n",
    "print file_list\n",
    "file_queue = tf.train.string_input_producer(file_list, num_epochs=1)\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(file_queue)\n",
    "\n",
    "# Define how to parse the example\n",
    "context_features = {\n",
    "    \"length\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features = {\n",
    "    \"inputs\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    " \n",
    "# Parse the example\n",
    "context, sequence = tf.parse_single_sequence_example(\n",
    "    serialized=serialized_example,\n",
    "    context_features=context_features,\n",
    "    sequence_features=sequence_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Batch the variable length tensor with dynamic padding\n",
    "batch_lengths, batch_sequences, batch_labels = tf.train.batch(\n",
    "    [context[\"length\"], sequence[\"inputs\"], sequence[\"labels\"]],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dynamic_pad=True,\n",
    "    allow_smaller_final_batch=True,\n",
    "    name=\"input_batching\")\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        for i in range(2):\n",
    "            lens, seqs, lbls = sess.run([batch_lengths, batch_sequences, batch_labels])\n",
    "            print('actual lengths =', lens)\n",
    "            print('sequences = ', seqs)\n",
    "            print('labels = ', lbls)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Winston/workspace/LSTM/Sequence_test1.tfr']\n",
      "('actual_lengths =', array([3, 3, 2, 4], dtype=int32))\n",
      "('sequences = ', array([[1, 2, 3, 0],\n",
      "       [4, 5, 1, 0],\n",
      "       [1, 2, 0, 0],\n",
      "       [0, 2, 4, 7]]))\n",
      "('labels = ', array([[0, 1, 0, 0],\n",
      "       [1, 0, 0, 0],\n",
      "       [1, 1, 0, 0],\n",
      "       [0, 1, 1, 0]]))\n",
      "('actual_lengths =', array([2, 5, 3], dtype=int32))\n",
      "('sequences = ', array([[9, 8, 0, 0, 0],\n",
      "       [5, 4, 3, 2, 1],\n",
      "       [3, 6, 9, 0, 0]]))\n",
      "('labels = ', array([[1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 0],\n",
      "       [1, 0, 1, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "## SequenceExample (2: deserialize/read part-2, no use of context feature in TFR)\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "file_list = [os.path.join(os.getcwd(), 'Sequence_test1.tfr')]\n",
    "print file_list\n",
    "file_queue = tf.train.string_input_producer(file_list, num_epochs=1)\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(file_queue)\n",
    "\n",
    "# Define how to parse the example\n",
    "sequence_features = {\n",
    "    \"inputs\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    " \n",
    "# Parse the example\n",
    "_, sequence = tf.parse_single_sequence_example(\n",
    "    serialized=serialized_example,\n",
    "    sequence_features=sequence_features)\n",
    "actual_length = tf.shape(sequence[\"inputs\"])[0]\n",
    "\n",
    "# # Batch the variable length tensor with dynamic padding\n",
    "batch_lengths, batch_sequences, batch_labels = tf.train.batch(\n",
    "    [actual_length, sequence[\"inputs\"], sequence[\"labels\"]],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dynamic_pad=True,\n",
    "    allow_smaller_final_batch=True,\n",
    "    name=\"input_batching\")\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        for i in range(2):\n",
    "            lens, seqs, lbls = sess.run([batch_lengths, batch_sequences, batch_labels])\n",
    "            print('actual_lengths =', lens) \n",
    "            print('sequences = ', seqs)\n",
    "            print('labels = ', lbls)      \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Another reference, code snippet of Tensorflow/Magenta/sequence_example_lib.py\n",
    "\n",
    "def make_sequence_example(inputs, labels):\n",
    "  \"\"\"Returns a SequenceExample for the given inputs and labels.\n",
    "  Args:\n",
    "    inputs: A list of input vectors. Each input vector is a list of floats.\n",
    "    labels: A list of ints.\n",
    "  Returns:\n",
    "    A tf.train.SequenceExample containing inputs and labels.\n",
    "  \"\"\"\n",
    "  input_features = [\n",
    "      tf.train.Feature(float_list=tf.train.FloatList(value=input_))\n",
    "      for input_ in inputs]\n",
    "  label_features = [\n",
    "      tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "      for label in labels]\n",
    "  feature_list = {\n",
    "      'inputs': tf.train.FeatureList(feature=input_features),\n",
    "      'labels': tf.train.FeatureList(feature=label_features)\n",
    "  }\n",
    "  feature_lists = tf.train.FeatureLists(feature_list=feature_list)\n",
    "  return tf.train.SequenceExample(feature_lists=feature_lists)\n",
    "\n",
    "\n",
    "def get_padded_batch(file_list, batch_size, input_size,\n",
    "                     num_enqueuing_threads=4):\n",
    "  \"\"\"Reads batches of SequenceExamples from TFRecords and pads them.\n",
    "  Can deal with variable length SequenceExamples by padding each batch to the\n",
    "  length of the longest sequence with zeros.\n",
    "  Args:\n",
    "    file_list: A list of paths to TFRecord files containing SequenceExamples.\n",
    "    batch_size: The number of SequenceExamples to include in each batch.\n",
    "    input_size: The size of each input vector. The returned batch of inputs\n",
    "        will have a shape [batch_size, num_steps, input_size].\n",
    "    num_enqueuing_threads: The number of threads to use for enqueuing\n",
    "        SequenceExamples.\n",
    "  Returns:\n",
    "    inputs: A tensor of shape [batch_size, num_steps, input_size] of floats32s.\n",
    "    labels: A tensor of shape [batch_size, num_steps] of int64s.\n",
    "    lengths: A tensor of shape [batch_size] of int32s. The lengths of each\n",
    "        SequenceExample before padding.\n",
    "  \"\"\"\n",
    "  file_queue = tf.train.string_input_producer(file_list)\n",
    "  reader = tf.TFRecordReader()\n",
    "  _, serialized_example = reader.read(file_queue)\n",
    "\n",
    "  sequence_features = {\n",
    "      'inputs': tf.FixedLenSequenceFeature(shape=[input_size],\n",
    "                                           dtype=tf.float32),\n",
    "      'labels': tf.FixedLenSequenceFeature(shape=[],\n",
    "                                           dtype=tf.int64)}\n",
    "\n",
    "  _, sequence = tf.parse_single_sequence_example(\n",
    "      serialized_example, sequence_features=sequence_features)\n",
    "\n",
    "  length = tf.shape(sequence['inputs'])[0]\n",
    "\n",
    "  queue = tf.PaddingFIFOQueue(\n",
    "      capacity=1000,\n",
    "      dtypes=[tf.float32, tf.int64, tf.int32],\n",
    "      shapes=[(None, input_size), (None,), ()])\n",
    "\n",
    "  enqueue_ops = [queue.enqueue([sequence['inputs'],\n",
    "                                sequence['labels'],\n",
    "                                length])] * num_enqueuing_threads\n",
    "  tf.train.add_queue_runner(tf.train.QueueRunner(queue, enqueue_ops))\n",
    "  return queue.dequeue_many(batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
