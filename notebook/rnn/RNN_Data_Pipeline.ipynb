{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 2 0 0 0]\n",
      " [1 2 3 0 0]\n",
      " [1 2 3 4 0]\n",
      " [1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "## BATCHING & PADDING DATA (high-level approach)\n",
    "################################################\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# [0, 1, 2, 3, 4 ,...]\n",
    "x = tf.range(1, 10, name=\"x\")\n",
    " \n",
    "# A queue that outputs 0,1,2,3,...\n",
    "range_q = tf.train.range_input_producer(limit=10, shuffle=False)\n",
    "slice_end = range_q.dequeue()\n",
    " \n",
    "# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\n",
    "y = tf.slice(x, [0], [slice_end], name=\"y\")\n",
    "\n",
    "    \n",
    "# Batch the variable length tensor with dynamic padding\n",
    "batched_data = tf.train.batch(\n",
    "    tensors=[y],\n",
    "    batch_size=6,\n",
    "    dynamic_pad=True,\n",
    "    name=\"y_batch\"\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        result = sess.run(batched_data)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    print(result)\n",
    "    coord.join(threads)\n",
    "\n",
    "# Run the graph\n",
    "# tf.contrib.learn takes care of starting the queues for us\n",
    "#res = tf.contrib.learn.run_n({\"y\": batched_data}, n=1, feed_dict=None)\n",
    " \n",
    "# Print the result\n",
    "#print(\"Batch shape: {}\".format(res[0][\"y\"].shape))\n",
    "#print(res[0][\"y\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 2 0 0 0]\n",
      " [1 2 3 0 0]\n",
      " [1 2 3 4 0]\n",
      " [1 2 3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "## BATCHING & PADDING DATA (low-level approach)\n",
    "################################################\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# [0, 1, 2, 3, 4 ,...]\n",
    "x = tf.range(1, 10, name=\"x\")\n",
    " \n",
    "# A queue that outputs 0,1,2,3,...\n",
    "range_q = tf.train.range_input_producer(limit=10, shuffle=False)\n",
    "slice_end = range_q.dequeue()\n",
    " \n",
    "# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....\n",
    "y = tf.slice(x, [0], [slice_end], name=\"y\")\n",
    "\n",
    "    \n",
    "# Batch the variable length tensor with PaddingFIFOQueue\n",
    "padding_q = tf.PaddingFIFOQueue(\n",
    "    capacity=10,\n",
    "    dtypes=tf.int32,\n",
    "    shapes=[[None]])\n",
    "enqueue_op = padding_q.enqueue([y])\n",
    "qr = tf.train.QueueRunner(padding_q, [enqueue_op])\n",
    "tf.train.add_queue_runner(qr)\n",
    "batched_data = padding_q.dequeue_many(6)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        result = sess.run(batched_data)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    print(result)\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Winston/workspace/LSTM/Sequence_test_1.tfr']\n",
      "('actual_lengths =', array([3, 3, 2, 4]))\n",
      "batch_size=4, time_steps=4\n",
      "('sequences = ', array([[ 1.,  2.,  3.,  0.],\n",
      "       [ 4.,  5.,  1.,  0.],\n",
      "       [ 1.,  2.,  0.,  0.],\n",
      "       [ 0.,  2.,  4.,  7.]], dtype=float32))\n",
      "('labels = ', array([[0, 1, 0, 0],\n",
      "       [1, 0, 0, 0],\n",
      "       [1, 1, 0, 0],\n",
      "       [0, 1, 1, 0]]))\n",
      "('actual_lengths =', array([2, 5, 3]))\n",
      "batch_size=3, time_steps=5\n",
      "('sequences = ', array([[ 9.,  8.,  0.,  0.,  0.],\n",
      "       [ 5.,  4.,  3.,  2.,  1.],\n",
      "       [ 3.,  6.,  9.,  0.,  0.]], dtype=float32))\n",
      "('labels = ', array([[1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 0],\n",
      "       [1, 0, 1, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "## SequenceExample 1 [leverage context feature in TFR]\n",
    "## Note:\n",
    "##      input feature is simply a float32 per time-step, \n",
    "##      each sequence has different time-steps\n",
    "#############################################################\n",
    "\n",
    "### 1: serialize/write part\n",
    "\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sequences = [[1., 2., 3.], [4., 5., 1.], [1., 2.], [0., 2., 4., 7.], [9., 8.], [5., 4., 3., 2., 1.], [3., 6., 9.]]\n",
    "label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1], [0, 1, 1, 0], [1, 0], [0, 1, 1, 0, 0], [1, 0, 1]]\n",
    "\n",
    "# inputs: A list of float32\n",
    "# labels: A list of int64\n",
    "def make_sequence_example(inputs, labels):\n",
    "    # A non-sequential feature of our example\n",
    "    sequence_length = len(inputs)\n",
    "    context_features = {\n",
    "        'length': tf.train.Feature(int64_list=tf.train.Int64List(value=[sequence_length]))\n",
    "    }\n",
    "    context = tf.train.Features(feature=context_features)\n",
    "    # Feature lists for the two sequential features of our example\n",
    "    input_features = [tf.train.Feature(float_list=tf.train.FloatList(value=[input_])) for input_ in inputs]\n",
    "    label_features = [tf.train.Feature(int64_list=tf.train.Int64List(value=[label])) for label in labels]\n",
    "    feature_list = {\n",
    "        'inputs': tf.train.FeatureList(feature=input_features),\n",
    "        'labels': tf.train.FeatureList(feature=label_features)\n",
    "    }\n",
    "    feature_lists = tf.train.FeatureLists(feature_list=feature_list)\n",
    "    return tf.train.SequenceExample(context=context, feature_lists=feature_lists)\n",
    " \n",
    "# Write all examples into a TFRecords file\n",
    "output_file = os.path.join(os.getcwd(), 'Sequence_test_1.tfr')\n",
    "writer = tf.python_io.TFRecordWriter(output_file)\n",
    "for sequence, label_sequence in zip(sequences, label_sequences):\n",
    "    ex = make_sequence_example(sequence, label_sequence)\n",
    "    writer.write(ex.SerializeToString())\n",
    "writer.close()\n",
    "\n",
    "# Alternative:\n",
    "# def make_sequence_example(inputs, labels):\n",
    "#     # The object we return\n",
    "#     ex = tf.train.SequenceExample()\n",
    "#     # A non-sequential feature of our example\n",
    "#     sequence_length = len(inputs)\n",
    "#     ex.context.feature[\"length\"].int64_list.value.append(sequence_length)\n",
    "#     # Feature lists for the two sequential features of our example\n",
    "#     fl_inputs = ex.feature_lists.feature_list[\"inputs\"]\n",
    "#     fl_labels = ex.feature_lists.feature_list[\"labels\"]\n",
    "#     for _input, _label in zip(inputs, labels):\n",
    "#         fl_inputs.feature.add().float_list.value.append(_input)\n",
    "#         fl_labels.feature.add().int64_list.value.append(_label)\n",
    "#     return ex  \n",
    "\n",
    "\n",
    "\n",
    "### 2: deserialize/read part\n",
    "tf.reset_default_graph()\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "file_list = [os.path.join(os.getcwd(), 'Sequence_test_1.tfr')]\n",
    "print file_list\n",
    "file_queue = tf.train.string_input_producer(file_list, num_epochs=1)\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(file_queue)\n",
    "\n",
    "# Define how to parse the example\n",
    "context_features = {\n",
    "    \"length\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features = {\n",
    "    \"inputs\": tf.FixedLenSequenceFeature([], dtype=tf.float32),\n",
    "    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    " \n",
    "# Parse the example\n",
    "context, sequence = tf.parse_single_sequence_example(\n",
    "    serialized=serialized_example,\n",
    "    context_features=context_features,\n",
    "    sequence_features=sequence_features)\n",
    "\n",
    "\n",
    "# Batch the variable length tensor with dynamic padding\n",
    "batch_lengths, batch_sequences, batch_labels = tf.train.batch(\n",
    "    [context[\"length\"], sequence[\"inputs\"], sequence[\"labels\"]],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dynamic_pad=True,\n",
    "    allow_smaller_final_batch=True,\n",
    "    name=\"input_batching\")\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        for i in range(2):\n",
    "            lens, seqs, lbls = sess.run([batch_lengths, batch_sequences, batch_labels])\n",
    "            print('actual_lengths =', lens)\n",
    "            print('batch_size=%d, time_steps=%d' % (lbls.shape[0],lbls.shape[1]))\n",
    "            print('sequences = ', seqs)\n",
    "            print('labels = ', lbls)   \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Winston/workspace/LSTM/Sequence_test_2.tfr']\n",
      "('actual_lengths =', array([3, 3, 2, 4], dtype=int32))\n",
      "batch_size=4, time_steps=4\n",
      "('sequences = ', array([[ 1.,  2.,  3.,  0.],\n",
      "       [ 4.,  5.,  1.,  0.],\n",
      "       [ 1.,  2.,  0.,  0.],\n",
      "       [ 0.,  2.,  4.,  7.]], dtype=float32))\n",
      "('labels = ', array([[0, 1, 0, 0],\n",
      "       [1, 0, 0, 0],\n",
      "       [1, 1, 0, 0],\n",
      "       [0, 1, 1, 0]]))\n",
      "('actual_lengths =', array([2, 5, 3], dtype=int32))\n",
      "batch_size=3, time_steps=5\n",
      "('sequences = ', array([[ 9.,  8.,  0.,  0.,  0.],\n",
      "       [ 5.,  4.,  3.,  2.,  1.],\n",
      "       [ 3.,  6.,  9.,  0.,  0.]], dtype=float32))\n",
      "('labels = ', array([[1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 0],\n",
      "       [1, 0, 1, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "## SequenceExample 2 [no use of context feature in TFR]\n",
    "## Note:\n",
    "##      input feature is simply a float32 per time-step, \n",
    "##      each sequence has different time-steps\n",
    "#############################################################\n",
    "\n",
    "### 1: serialize/write part \n",
    "\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sequences = [[1., 2., 3.], [4., 5., 1.], [1., 2.], [0., 2., 4., 7.], [9., 8.], [5., 4., 3., 2., 1.], [3., 6., 9.]]\n",
    "label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1], [0, 1, 1, 0], [1, 0], [0, 1, 1, 0, 0], [1, 0, 1]]\n",
    "\n",
    "# inputs: A list of float32\n",
    "# labels: A list of int64\n",
    "def make_sequence_example(inputs, labels):\n",
    "    # Feature lists for the two sequential features of our example\n",
    "    input_features = [tf.train.Feature(float_list=tf.train.FloatList(value=[input_])) for input_ in inputs]\n",
    "    label_features = [tf.train.Feature(int64_list=tf.train.Int64List(value=[label])) for label in labels]\n",
    "    feature_list = {\n",
    "        'inputs': tf.train.FeatureList(feature=input_features),\n",
    "        'labels': tf.train.FeatureList(feature=label_features)\n",
    "    }\n",
    "    feature_lists = tf.train.FeatureLists(feature_list=feature_list)\n",
    "    return tf.train.SequenceExample(feature_lists=feature_lists)\n",
    " \n",
    "# Write all examples into a TFRecords file\n",
    "output_file = os.path.join(os.getcwd(), 'Sequence_test_2.tfr')\n",
    "writer = tf.python_io.TFRecordWriter(output_file)\n",
    "for sequence, label_sequence in zip(sequences, label_sequences):\n",
    "    ex = make_sequence_example(sequence, label_sequence)\n",
    "    writer.write(ex.SerializeToString())\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "### 2: deserialize/read part\n",
    "tf.reset_default_graph()\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "file_list = [os.path.join(os.getcwd(), 'Sequence_test_2.tfr')]\n",
    "print file_list\n",
    "file_queue = tf.train.string_input_producer(file_list, num_epochs=1)\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(file_queue)\n",
    "\n",
    "# Define how to parse the example\n",
    "sequence_features = {\n",
    "    \"inputs\": tf.FixedLenSequenceFeature([], dtype=tf.float32),\n",
    "    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    " \n",
    "# Parse the example\n",
    "_, sequence = tf.parse_single_sequence_example(\n",
    "    serialized=serialized_example,\n",
    "    sequence_features=sequence_features)\n",
    "actual_length = tf.shape(sequence[\"inputs\"])[0]\n",
    "\n",
    "# Batch the variable length tensor with dynamic padding\n",
    "batch_lengths, batch_sequences, batch_labels = tf.train.batch(\n",
    "    [actual_length, sequence[\"inputs\"], sequence[\"labels\"]],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dynamic_pad=True,\n",
    "    allow_smaller_final_batch=True,\n",
    "    name=\"input_batching\")\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        for i in range(2):\n",
    "            lens, seqs, lbls = sess.run([batch_lengths, batch_sequences, batch_labels])\n",
    "            print('actual_lengths =', lens)\n",
    "            print('batch_size=%d, time_steps=%d' % (lbls.shape[0],lbls.shape[1]))\n",
    "            print('sequences = ', seqs)\n",
    "            print('labels = ', lbls) \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Winston/workspace/LSTM/Sequence_test_3.tfr']\n",
      "('actual_lengths =', array([3, 3, 2, 4], dtype=int32))\n",
      "batch_size=4, time_steps=4\n",
      "('sequences = ', array([[[  1.,   1.,   1.,   1.,   1.],\n",
      "        [  2.,   3.,   4.,   5.,   6.],\n",
      "        [  3.,   2.,   1.,   0.,  -1.],\n",
      "        [  0.,   0.,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  4.,   3.,   1.,   2.,   5.],\n",
      "        [  5.,   5.,   5.,   5.,   5.],\n",
      "        [  1.,   2.,   3.,   4.,   5.],\n",
      "        [  0.,   0.,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  1.,   0.,   0.,   0.,   1.],\n",
      "        [  2.,   2.,   2.,   2.,   2.],\n",
      "        [  0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0.,   0.,   0.],\n",
      "        [  2.,   1.,   0.,  -1.,  -2.],\n",
      "        [  4.,   8.,  12.,  16.,  20.],\n",
      "        [  7.,   7.,   7.,   0.,   1.]]], dtype=float32))\n",
      "('labels = ', array([[0, 1, 0, 0],\n",
      "       [1, 0, 0, 0],\n",
      "       [1, 1, 0, 0],\n",
      "       [0, 1, 1, 0]]))\n",
      "('actual_lengths =', array([2, 5, 3], dtype=int32))\n",
      "batch_size=3, time_steps=5\n",
      "('sequences = ', array([[[ 9.,  9.,  9.,  9.,  9.],\n",
      "        [ 8.,  8.,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 5.,  4.,  3.,  2.,  1.],\n",
      "        [ 4.,  4.,  8.,  8.,  8.],\n",
      "        [ 3.,  3.,  3.,  6.,  6.],\n",
      "        [ 2.,  2.,  2.,  2.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.]],\n",
      "\n",
      "       [[ 3.,  0.,  3.,  0.,  3.],\n",
      "        [ 6.,  8.,  3.,  1.,  1.],\n",
      "        [ 9.,  9.,  9.,  9.,  8.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.]]], dtype=float32))\n",
      "('labels = ', array([[1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 0],\n",
      "       [1, 0, 1, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "## SequenceExample 3 [no use of context feature in TFR]\n",
    "## Note:\n",
    "##      input feature is a float32 vector per time-step,\n",
    "##      input feature dimension is the same for all sequences,\n",
    "##      acutal time-steps may differ for each sequence\n",
    "#############################################################\n",
    "\n",
    "### 1: serialize/write part \n",
    "\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "FEATURE_SIZE_PER_TIMESTEP = 5\n",
    "sequences = [[[1.,1.,1.,1.,1.], [2.,3.,4.,5.,6.], [3.,2.,1.,0.,-1.]], \n",
    "             [[4.,3.,1.,2.,5.], [5.,5.,5.,5.,5.], [1.,2.,3.,4.,5.]], \n",
    "             [[1.,0.,0.,0.,1.], [2.,2.,2.,2.,2.]], \n",
    "             [[0.,0.,0.,0.,0.], [2.,1.,0.,-1.,-2.], [4.,8.,12.,16.,20.], [7.,7.,7.,0.,1.]], \n",
    "             [[9.,9.,9.,9.,9.], [8.,8.,1.,1.,1.]], \n",
    "             [[5.,4.,3.,2.,1.], [4.,4.,8.,8.,8.], [3.,3.,3.,6.,6.], [2.,2.,2.,2.,1.], [1.,1.,1.,1.,1.]], \n",
    "             [[3.,0.,3.,0.,3.], [6.,8.,3.,1.,1.], [9.,9.,9.,9.,8.]]]\n",
    "label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1], [0, 1, 1, 0], [1, 0], [0, 1, 1, 0, 0], [1, 0, 1]]\n",
    "\n",
    "# inputs: A list of input vectors, each input vector is a list of float32 (entries #: FEATURE_SIZE_PER_TIMESTEP)\n",
    "# labels: A list of int64\n",
    "def make_sequence_example(inputs, labels):\n",
    "    input_features = [tf.train.Feature(float_list=tf.train.FloatList(value=input_)) for input_ in inputs]\n",
    "    label_features = [tf.train.Feature(int64_list=tf.train.Int64List(value=[label])) for label in labels]\n",
    "    feature_list = {\n",
    "        'inputs': tf.train.FeatureList(feature=input_features),\n",
    "        'labels': tf.train.FeatureList(feature=label_features)\n",
    "    }\n",
    "    feature_lists = tf.train.FeatureLists(feature_list=feature_list)\n",
    "    return tf.train.SequenceExample(feature_lists=feature_lists)\n",
    "\n",
    "# Write all examples into a TFRecords file\n",
    "output_file = os.path.join(os.getcwd(), 'Sequence_test_3.tfr')\n",
    "writer = tf.python_io.TFRecordWriter(output_file)\n",
    "for sequence, label_sequence in zip(sequences, label_sequences):\n",
    "    ex = make_sequence_example(sequence, label_sequence)\n",
    "    writer.write(ex.SerializeToString())\n",
    "writer.close()\n",
    "\n",
    "\n",
    "## 2: deserialize/read part\n",
    "tf.reset_default_graph()\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "FEATURE_SIZE_PER_TIMESTEP = 5\n",
    "\n",
    "file_list = [os.path.join(os.getcwd(), 'Sequence_test_3.tfr')]\n",
    "print file_list\n",
    "file_queue = tf.train.string_input_producer(file_list, num_epochs=1)\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(file_queue)\n",
    "\n",
    "# Define how to parse the example\n",
    "sequence_features = {\n",
    "    \"inputs\": tf.FixedLenSequenceFeature([FEATURE_SIZE_PER_TIMESTEP], dtype=tf.float32),\n",
    "    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    " \n",
    "# Parse the example\n",
    "_, sequence = tf.parse_single_sequence_example(\n",
    "    serialized=serialized_example,\n",
    "    sequence_features=sequence_features)\n",
    "actual_length = tf.shape(sequence[\"inputs\"])[0]\n",
    "\n",
    "# Batch the variable length tensor with dynamic padding\n",
    "batch_lengths, batch_sequences, batch_labels = tf.train.batch(\n",
    "    [actual_length, sequence[\"inputs\"], sequence[\"labels\"]],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dynamic_pad=True,\n",
    "    allow_smaller_final_batch=True,\n",
    "    name=\"input_batching\")\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try: \n",
    "        for i in range(2):\n",
    "            lens, seqs, lbls = sess.run([batch_lengths, batch_sequences, batch_labels])\n",
    "            print('actual_lengths =', lens)\n",
    "            print('batch_size=%d, time_steps=%d' % (lbls.shape[0],lbls.shape[1]))\n",
    "            print('sequences = ', seqs)\n",
    "            print('labels = ', lbls)      \n",
    "    except tf.errors.OutOfRangeError as e:\n",
    "        print('Done')\n",
    "        print(e.error_code, e.message)\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
